# Comparative Evaluation of Text Summarizing Models

## Project Overview

This project focuses on the comparative evaluation of three state-of-the-art text summarization models—BERT, XLNet, and GPT-2—applied to content extracted from PDF documents. The goal is to enhance the efficiency of text summarization for PDFs by rigorously comparing the performance of these models.

## Key Features

- **PDF Content Extraction:** Robust mechanisms for extracting textual content from PDF documents, providing a foundation for analysis.

- **Model Selection:** Careful evaluation and selection of BERT, XLNet, and GPT-2, renowned for their natural language processing capabilities.

- **Comparative Study:** In-depth analysis considering summarization accuracy, coherence, and computational efficiency, enabling informed model selection.

- **Implementation and Fine-Tuning:** Implementation of models with fine-tuning tailored to the specific requirements of summarizing PDF content.

- **Performance Metrics:** Rigorous application of performance metrics to quantitatively measure the efficacy of each model.

- **Results and Findings:** Compilation and analysis of results, offering insights into the strengths and limitations of each model.

- **Research Paper:** Authoring a research paper documenting methodology, experimental setup, findings, and implications for potential publication in relevant conferences or journals.

## Getting Started

1. **Clone the Repository:**
   ```bash
   git clone https://github.com/chirayu-xx/text-summarization-comparison.git
   ```

2. **Install Dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run Comparative Evaluation:**
   ```bash
   python evaluate_models.py
   ```

## Folder Structure

- **`data/`:** Contains the PDF datasets for evaluation.
- **`models/`:** Includes the implementations and fine-tuned versions of BERT, XLNet, and GPT-2.
- **`results/`:** Stores the output and analysis results.



## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Special thanks to the creators and maintainers of BERT, XLNet, and GPT-2 for their invaluable contributions to the field of natural language processing.
- Inspired by the need for efficient text summarization in the context of PDF documents.
